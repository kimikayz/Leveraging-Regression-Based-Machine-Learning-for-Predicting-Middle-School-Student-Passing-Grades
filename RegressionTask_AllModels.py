# -*- coding: utf-8 -*-
"""5. RegressionTask_AllModels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_wSIcthtAJ1onJv2oBKQR0NZ_DD2hvxa
"""

# Menghubungkan Google Drive ke Google Colab untuk akses penyimpanan data
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Mengubah direktori kerja ke folder di Google Drive
# %cd /content/drive/MyDrive/Semester/Sem 5/Research Methodology in Computer Science/Kelompok 17

# Mengimpor library yang diperlukan
import warnings  # Library untuk mengatur dan menyaring peringatan
import numpy as np  # Library untuk operasi numerik pada array
import pandas as pd  # Library untuk manipulasi dan analisis data
import seaborn as sns  # Library untuk visualisasi data berbasis matplotlib
import matplotlib.pyplot as plt  # Library untuk membuat visualisasi data
from scipy import stats  # Library untuk analisis statistik
from math import sqrt # Library untuk menghitung akar kuadrat

# Menonaktifkan peringatan agar tidak mengganggu output
warnings.filterwarnings('ignore')

# Mengimpor modul 'files' dari 'google.colab' untuk mengupload file
from google.colab import files

# Memanggil fungsi 'upload' untuk mengupload file dari komputer pengguna
uploaded = files.upload()

"""# Exploratory Data Analysis"""

# Membaca dataset
df = pd.read_csv("StudentPerformance.csv")

# Menampilkan beberapa baris pertama
df.head()

# Menampilkan jumlah baris dan kolom dalam dataset
df.shape

# Menampilkan informasi ringkas tentang dataset
# Termasuk jumlah entri, jumlah kolom, nama kolom, tipe data, dan jumlah nilai non-null
df.info()

# Menghitung jumlah nilai yang hilang (null) pada setiap kolom dalam DataFrame
df.isnull().sum()

# Mengecek jumlah data duplikat dalam dataframe
df.duplicated().value_counts()

# Menghitung jumlah nilai unik yang ada di setiap kolom dalam DataFrame
df.nunique()

# Menampilkan statistik deskriptif dari DataFrame untuk kolom numerik
df.describe()

# Mengelompokkan DataFrame berdasarkan kolom 'failures' dan 'age',
# Menghitung jumlah kemunculan masing-masing kombinasi, dan mereset index
failure_counts = df.groupby(["failures", "age"]).size().reset_index(name="count")

# Menampilkan DataFrame yang menunjukkan jumlah kegagalan ('failures') berdasarkan usia ('age')
print(failure_counts)

# Membuat plot count menggunakan seaborn untuk menampilkan jumlah 'failures',
# dibedakan berdasarkan 'age' dan ditampilkan secara horizontal
sns.countplot(data=df, y='age', hue='failures', palette="rocket_r")

# Menetapkan judul untuk plot
plt.title('Count of Failures by Age')

# Memberikan label untuk sumbu y
plt.ylabel('Age')

# Membuat pivot table untuk menghitung jumlah kemunculan 'failures' untuk setiap tipe 'Pstatus'
pivot_table = df.pivot_table(index='failures', columns='Pstatus', aggfunc='size')

# Membuat heatmap menggunakan seaborn, dengan anotasi, skema warna, dan format angka untuk anotasi
sns.heatmap(pivot_table, annot=True, cmap='tab20c_r', fmt='g')

# Menambahkan judul pada plot
plt.title('Distribusi Jumlah Kegagalan Berdasarkan Tipe Pstatus')

# Menambahkan label pada sumbu x
plt.xlabel('Tipe Pstatus')

# Menambahkan label pada sumbu y
plt.ylabel('Jumlah Kegagalan')

# Membuat subplot dengan 1 baris dan 3 kolom, dengan setiap plot berbagi sumbu y
fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=False)

# Melakukan iterasi melalui periode nilai (G1, G2, G3) dan membuat plot
for i, grade_period in enumerate(['G1', 'G2', 'G3']):  # Melakukan loop untuk setiap kolom nilai
    sns.countplot(ax=axes[i], data=df, y=grade_period, hue="Pstatus", palette="Blues")
    # Membuat countplot untuk masing-masing periode nilai, dengan hue 'Pstatus' dan skema warna biru

    axes[i].set_title(f'{grade_period} vs Pstatus')  # Menambahkan judul pada setiap plot
    axes[i].set_ylabel("Grade")  # Menambahkan label untuk sumbu y pada setiap plot

# Menampilkan semua plot
plt.show()

# Membuat subplot dengan 1 baris dan 3 kolom, serta menyesuaikan ukuran figure
fig, axes = plt.subplots(1, 3, figsize=(25, 15))

# Melakukan iterasi melalui periode nilai (G1, G2, G3) dan membuat plot
for i, grade in enumerate(['G1', 'G2', 'G3']):  # Melakukan loop untuk setiap kolom nilai
    sns.countplot(data=df, y=grade, hue='failures', ax=axes[i], palette='Set2', dodge=True)
    # Membuat countplot untuk masing-masing periode nilai (G1, G2, G3)
    # dengan hue berdasarkan 'failures' dan skema warna 'Set2'

    axes[i].set_title(f'Failure vs {grade}')  # Menambahkan judul pada setiap subplot
    axes[i].set_ylabel('Grade')  # Menambahkan label untuk sumbu y
    axes[i].set_xlabel('Count')  # Menambahkan label untuk sumbu x

# Menampilkan semua plot
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Membuat daftar kolom yang akan divisualisasikan terhadap G3
columns_to_visualize = ['freetime', 'health', 'absences', 'G1', 'G2']

# Membuat subplot dengan jumlah baris sesuai dengan jumlah kolom
fig, axes = plt.subplots(len(columns_to_visualize), 1, figsize=(10, 25), sharey=False)

# Iterasi melalui setiap kolom untuk membuat scatter plot
for i, column in enumerate(columns_to_visualize):
    # Membuat scatter plot untuk setiap kolom terhadap G3
    sns.scatterplot(ax=axes[i], x=df[column], y=df['G3'], color='blue', alpha=0.7)

    # Menambahkan judul pada setiap plot
    axes[i].set_title(f'{column} vs G3', fontsize=14)

    # Menambahkan label pada sumbu x
    axes[i].set_xlabel(column, fontsize=12)

    # Menambahkan label pada sumbu y
    axes[i].set_ylabel('G3', fontsize=12)

# Menambahkan spasi antar subplot agar tidak saling tumpang tindih
plt.tight_layout()

# Menampilkan plot
plt.show()

# Scatter plot untuk kolom 'freetime' vs G3
plt.figure(figsize=(8, 6))
# Membuat scatter plot untuk melihat hubungan antara freetime dan G3
sns.scatterplot(x=df['freetime'], y=df['G3'], color='green', alpha=0.7)
# Menambahkan judul, label sumbu x, dan y
plt.title('Freetime vs G3', fontsize=16)
plt.xlabel('Freetime', fontsize=12)
plt.ylabel('G3', fontsize=12)
plt.grid(alpha=0.3)  # Menambahkan grid untuk memperjelas plot
plt.show()

# Bar chart untuk kolom 'health' vs rata-rata G3
plt.figure(figsize=(8, 6))
# Menghitung rata-rata G3 berdasarkan kategori health
health_mean = df.groupby('health')['G3'].mean()
# Membuat bar chart untuk hubungan health dan rata-rata G3
health_mean.plot(kind='bar', color='blue', alpha=0.8)
# Menambahkan judul, label sumbu x, dan y
plt.title('Average G3 by Health Level', fontsize=16)
plt.xlabel('Health Level', fontsize=12)
plt.ylabel('Average G3', fontsize=12)
plt.grid(alpha=0.3)  # Menambahkan grid
plt.xticks(rotation=0)  # Membuat label x tetap horizontal
plt.show()

# Pie chart untuk kolom 'absences' dalam kaitannya dengan jumlah siswa berdasarkan G3 >= 10
plt.figure(figsize=(15, 8))
# Membuat kategori siswa berdasarkan G3 >= 10
absences_high_grades = df[df['G3'] >= 10]['absences'].value_counts()
# Membuat pie chart untuk distribusi absences berdasarkan siswa dengan G3 >= 10
absences_high_grades.plot(kind='pie', autopct='%1.1f%%', startangle=140, colormap='Set3')
# Menambahkan judul
plt.title('Distribution of Absences for G3 >= 10', fontsize=16)
plt.ylabel('')  # Menghilangkan label default pada y
plt.show()

# Box plot untuk kolom 'G1' vs G3
plt.figure(figsize=(8, 6))
# Membuat box plot untuk hubungan G1 dan G3
sns.boxplot(x=df['G1'], y=df['G3'], palette='coolwarm')
# Menambahkan judul, label sumbu x, dan y
plt.title('G1 vs G3 (Box Plot)', fontsize=16)
plt.xlabel('G1', fontsize=12)
plt.ylabel('G3', fontsize=12)
plt.grid(alpha=0.3)  # Menambahkan grid
plt.show()

# Line plot untuk kolom 'G2' vs rata-rata G3
plt.figure(figsize=(8, 6))
# Menghitung rata-rata G3 berdasarkan kategori G2
g2_mean = df.groupby('G2')['G3'].mean()
# Membuat line plot untuk hubungan G2 dan rata-rata G3
plt.plot(g2_mean, marker='o', linestyle='-', color='purple', alpha=0.8)
# Menambahkan judul, label sumbu x, dan y
plt.title('Average G3 by G2', fontsize=16)
plt.xlabel('G2', fontsize=12)
plt.ylabel('Average G3', fontsize=12)
plt.grid(alpha=0.3)  # Menambahkan grid
plt.show()

# Melakukan iterasi untuk setiap kolom dalam DataFrame
for column in df.columns:
    # Menampilkan nama kolom
    print(column)
    # Menampilkan jumlah kemunculan nilai unik pada kolom tersebut
    print(df[column].value_counts())
    # Menambahkan pemisah antar kolom untuk kejelasan
    print('----------------------------------')

"""# Data Pre-Processing"""

# Mengimpor library yang diperlukan
from sklearn.preprocessing import LabelEncoder

# Membuat objek LabelEncoder untuk melakukan encoding data kategorikal
label_encoder = LabelEncoder()

# Daftar kolom yang akan di-encode
Columns = ["school", "sex", "address", "famsize", "Pstatus", "Mjob", "Fjob", "reason", "guardian",
           "schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet", "romantic"]

# Melakukan iterasi untuk setiap kolom dalam daftar Columns
for i in range(len(Columns)):
    # Mengambil nilai unik dari kolom yang sedang diproses
    Country_keys = df[Columns[i]]  # Mengambil data kolom
    Country_keys = Country_keys.tolist()  # Mengonversi data kolom menjadi list

    # Melakukan label encoding untuk data kolom yang sedang diproses
    Country_values = label_encoder.fit_transform(df[Columns[i]])  # Encode data kolom
    Country_values = Country_values.tolist()  # Mengonversi hasil encoding menjadi list

    # Memperbarui DataFrame dengan nilai hasil encoding
    df[Columns[i]] = label_encoder.fit_transform(df[Columns[i]])  # Update kolom dengan nilai encoded

    # Membuat dictionary yang memetakan nilai asli ke nilai encoded
    Country_dict = dict(zip(Country_keys, Country_values))

    # Menampilkan dictionary yang berisi mapping nilai asli ke nilai encoded
    print(Country_dict)

# Menghitung matriks korelasi untuk DataFrame
corr = df.corr()

# Membuat figure dengan ukuran besar untuk visualisasi yang lebih jelas
plt.figure(figsize=(50, 50))

# Membuat heatmap menggunakan seaborn, dengan anotasi dan skema warna biru
sns.heatmap(corr, annot=True, cmap="Blues")

# Menambahkan judul pada heatmap dengan ukuran font lebih besar
plt.title('Correlation Heatmap', fontsize=20)

# Menghitung matriks korelasi untuk DataFrame
corr = df.corr()

# Memfilter kolom yang berkaitan dengan G3
# Memilih hanya kolom dengan nilai korelasi yang tidak nol terhadap G3
correlation_with_G3 = corr['G3'].drop('G3')  # Menghapus korelasi diri sendiri (G3 dengan G3)

# Mengonversi hasil korelasi menjadi DataFrame agar lebih mudah dibaca
correlation_with_G3 = correlation_with_G3.reset_index()
correlation_with_G3.columns = ['Column', 'Correlation']  # Memberikan nama kolom

# Menampilkan daftar kolom beserta nilai korelasinya dengan G3
print("Kolom yang berkorelasi dengan G3:")
print(correlation_with_G3.sort_values(by='Correlation', ascending=False))  # Mengurutkan berdasarkan korelasi

# Menghitung nilai z-score absolut untuk setiap elemen dalam DataFrame hanya untuk kolom numerik
df_numeric = df.select_dtypes(include=[np.number])  # Memilih hanya kolom numerik
z_scores = np.abs(stats.zscore(df_numeric))  # Menghitung z-score untuk kolom numerik

# Menghitung bentuk (jumlah baris dan kolom) dari DataFrame setelah dihitung z-score
z_scores.shape  # Menampilkan jumlah baris dan kolom dari hasil z-score

# Menyaring DataFrame dengan menghapus outlier (nilai dengan z-score >= 3) pada semua kolom numerik
df_filtered = df[(z_scores < 3).all(axis=1)]  # Menyaring baris yang memiliki z-score >= 3 pada semua kolom numerik

# Menampilkan DataFrame setelah penyaringan untuk memeriksa hasilnya
df_filtered

"""## Menghilang Outliers pada Kolom Numerik yang Bukan Merupakan Angka Rating atau Jumlah"""

# Menentukan nama kolom yang ingin dianalisis
column = 'absences'

# Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3)
q1 = np.percentile(df[column], 25)  # Kuartil pertama (25th percentile)
q3 = np.percentile(df[column], 75)  # Kuartil ketiga (75th percentile)

# Menghitung Interquartile Range (IQR)
IQR = q3 - q1  # Rentang antara Q1 dan Q3

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
batas_bawah = q1 - (1.5 * IQR)  # Batas bawah untuk outlier
batas_atas = q3 + (1.5 * IQR)   # Batas atas untuk outlier

# Mencetak batas bawah dan batas atas
print(batas_bawah)
print(batas_atas)

# Menghapus data yang dianggap sebagai outlier berdasarkan batas bawah dan batas atas
df_numeric_clean = df_numeric[(df_numeric[column] >= batas_bawah) & (df_numeric[column] <= batas_atas)]

# Menampilkan jumlah baris dan kolom setelah menghapus outlier
df_numeric_clean.shape

# Menentukan nama kolom yang ingin dianalisis
column = 'age'

# Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) untuk kolom 'age'
q1 = np.percentile(df_numeric_clean[column], 25)  # Kuartil pertama (25th percentile)
q3 = np.percentile(df_numeric_clean[column], 75)  # Kuartil ketiga (75th percentile)

# Menghitung Interquartile Range (IQR)
IQR = q3 - q1  # Rentang antara Q1 dan Q3

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
batas_bawah = q1 - (1.5 * IQR)  # Batas bawah untuk outlier
batas_atas = q3 + (1.5 * IQR)   # Batas atas untuk outlier

# Mencetak batas bawah dan batas atas
print(batas_bawah)
print(batas_atas)

# Menghapus data yang dianggap sebagai outlier berdasarkan batas bawah dan batas atas untuk kolom 'age'
df_numeric_clean = df_numeric_clean[(df_numeric_clean[column] >= batas_bawah) & (df_numeric_clean[column] <= batas_atas)]

# Menampilkan jumlah baris dan kolom setelah menghapus outlier
df_numeric_clean.shape

# Menentukan nama kolom yang ingin dianalisis
column = 'G1'

# Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) untuk kolom 'G1'
q1 = np.percentile(df_numeric_clean[column], 25)  # Kuartil pertama (25th percentile)
q3 = np.percentile(df_numeric_clean[column], 75)  # Kuartil ketiga (75th percentile)

# Menghitung Interquartile Range (IQR)
IQR = q3 - q1  # Rentang antara Q1 dan Q3

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
batas_bawah = q1 - (1.5 * IQR)  # Batas bawah untuk outlier
batas_atas = q3 + (1.5 * IQR)   # Batas atas untuk outlier

# Mencetak batas bawah dan batas atas
print(batas_bawah)
print(batas_atas)

# Menghapus data yang dianggap sebagai outlier berdasarkan batas bawah dan batas atas untuk kolom 'G1'
df_numeric_clean = df_numeric_clean[(df_numeric_clean[column] >= batas_bawah) & (df_numeric_clean[column] <= batas_atas)]

# Menampilkan jumlah baris dan kolom setelah menghapus outlier
df_numeric_clean.shape

# Menentukan nama kolom yang ingin dianalisis
column = 'G2'

# Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) untuk kolom 'G2'
q1 = np.percentile(df_numeric_clean[column], 25)  # Kuartil pertama (25th percentile)
q3 = np.percentile(df_numeric_clean[column], 75)  # Kuartil ketiga (75th percentile)

# Menghitung Interquartile Range (IQR)
IQR = q3 - q1  # Rentang antara Q1 dan Q3

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
batas_bawah = q1 - (1.5 * IQR)  # Batas bawah untuk outlier
batas_atas = q3 + (1.5 * IQR)   # Batas atas untuk outlier

# Mencetak batas bawah dan batas atas
print(batas_bawah)
print(batas_atas)

# Menghapus data yang dianggap sebagai outlier berdasarkan batas bawah dan batas atas untuk kolom 'G2'
df_numeric_clean = df_numeric_clean[(df_numeric_clean[column] >= batas_bawah) & (df_numeric_clean[column] <= batas_atas)]

# Menampilkan jumlah baris dan kolom setelah menghapus outlier
df_numeric_clean.shape

# Menentukan nama kolom yang ingin dianalisis
column = 'G3'

# Menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) untuk kolom 'G3'
q1 = np.percentile(df_numeric_clean[column], 25)  # Kuartil pertama (25th percentile)
q3 = np.percentile(df_numeric_clean[column], 75)  # Kuartil ketiga (75th percentile)

# Menghitung Interquartile Range (IQR)
IQR = q3 - q1  # Rentang antara Q1 dan Q3

# Menentukan batas bawah dan batas atas untuk mendeteksi outlier
batas_bawah = q1 - (1.5 * IQR)  # Batas bawah untuk outlier
batas_atas = q3 + (1.5 * IQR)   # Batas atas untuk outlier

# Mencetak batas bawah dan batas atas
print(batas_bawah)
print(batas_atas)

# Menghapus data yang dianggap sebagai outlier berdasarkan batas bawah dan batas atas untuk kolom 'G3'
df_numeric_clean = df_numeric_clean[(df_numeric_clean[column] >= batas_bawah) & (df_numeric_clean[column] <= batas_atas)]

# Menampilkan jumlah baris dan kolom setelah menghapus outlier
df_numeric_clean.shape

"""# Feature Selection

Kami akan menerapkan metode pemilihan fitur yang dapat membantu kami untuk memilih fitur yang efektif dalam model daripada memilih semua fitur yang efektif dan fitur yang tidak efektif
"""

# Daftar kolom dan korelasinya
correlation_data = {
    "Column": [
        "G2", "G1", "Medu", "higher", "Fedu", "reason", "address", "sex",
        "Mjob", "paid", "internet", "studytime", "famsize", "nursery",
        "famrel", "Fjob", "absences", "activities", "freetime", "famsup",
        "school", "Walc", "Dalc", "Pstatus", "health", "guardian",
        "schoolsup", "traveltime", "romantic", "goout", "age", "failures"
    ],
    "Correlation": [
        0.904868, 0.801468, 0.217147, 0.182465, 0.152457, 0.121994,
        0.105756, 0.103456, 0.102082, 0.101996, 0.098483, 0.097820,
        0.081407, 0.051568, 0.051363, 0.042286, 0.034247, 0.016100,
        0.011307, -0.039157, -0.045017, -0.051939, -0.054660, -0.058009,
        -0.061335, -0.070109, -0.082788, -0.117142, -0.129970, -0.132791,
        -0.161579, -0.360415
    ]
}

# Membuat DataFrame dari data korelasi
correlation_df = pd.DataFrame(correlation_data)

# Memilih kolom dengan |korelasi| > 0.1 atau kolom 'failures'
selected_columns = correlation_df[
    (correlation_df["Correlation"].abs() > 0.1) | (correlation_df["Column"] == "failures")
]["Column"].tolist()

# Menampilkan kolom yang terpilih
print("Kolom yang dipilih berdasarkan korelasi:", selected_columns)

selected_columns = ['G2', 'G1', 'Medu', 'higher', 'Fedu', 'reason', 'address', 'sex', 'Mjob', 'paid', 'traveltime', 'romantic', 'goout', 'age', 'failures']
selected_columns

# Misalnya, data 'data' adalah DataFrame yang berisi dataset Anda
# Pisahkan fitur (X) dan target (y)
X = df[selected_columns]  # Memilih fitur berdasarkan kolom yang dipilih
y = df['G3']  # Gantilah dengan nama kolom target Anda

# Membagi data menjadi pelatihan dan pengujian
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Menggunakan RandomForestRegressor untuk memilih fitur berdasarkan pentingnya fitur
#from sklearn.ensemble import RandomForestRegressor  # Untuk model Random Forest Regressor

#model = RandomForestRegressor(random_state=42)
#model.fit(X_train, y_train)  # Melatih model

# Mendapatkan fitur yang paling penting
#feature_importances = model.feature_importances_

# Menyaring fitur berdasarkan pentingnya
#import pandas as pd

#important_features = pd.DataFrame({
#    'Feature': X_train.columns,
#    'Importance': feature_importances
#})

# Mengurutkan berdasarkan tingkat kepentingan fitur
#important_features = important_features.sort_values(by='Importance', ascending=False)

# Menampilkan fitur yang paling penting
#print(important_features)

# Menentukan fitur yang digunakan dalam model berdasarkan ranking pentingnya
#selected_features = important_features['Feature'].tolist()
#print("Fitur yang dipilih:", selected_features)

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_selection import SelectFromModel

# Asumsikan 'x' adalah matriks fitur (DataFrame) dan 'y' adalah variabel target

# Contoh x dan y
x = df[selected_columns]  # Atau gunakan semua fitur dalam DataFrame
y = df['G3']   # Ganti dengan kolom target yang sesuai

# Inisialisasi DecisionTreeClassifier dengan kriteria gini
# dtc = DecisionTreeClassifier(random_state=0, criterion='entropy')

# Inisialisasi SelectFromModel untuk memilih fitur
# selector = SelectFromModel(estimator=dtc)

# Melatih model
# selector.fit(x, y)

# Mendapatkan indeks fitur yang terpilih
# selected_features_idx = selector.get_support(indices=True)

# Memilih nama fitur yang sesuai berdasarkan indeks
# selected_features = x.columns[selected_features_idx].tolist()

# Menampilkan fitur yang terpilih
print("Selected Features:", selected_columns)

from sklearn.ensemble import RandomForestRegressor
import pandas as pd
import matplotlib.pyplot as plt

# Asumsikan df adalah DataFrame yang berisi data
# selected_columns berisi nama-nama fitur
X = df[selected_columns]  # Fitur
y = df['G3']  # Variabel target

# Inisialisasi RandomForestRegressor
model = RandomForestRegressor(random_state=42, n_estimators=100)

# Melatih model
model.fit(X, y)

# Mendapatkan pentingnya fitur
feature_importances = model.feature_importances_

# Membuat DataFrame untuk visualisasi yang lebih baik
importance_df = pd.DataFrame({
    'Feature': selected_columns,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Menampilkan DataFrame
print(importance_df)

# Membuat plot untuk pentingnya fitur
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Pentingnya Fitur')
plt.ylabel('Fitur')
plt.title('Pentingnya Fitur untuk Memprediksi G3')
plt.gca().invert_yaxis()  # Membalik sumbu y untuk keterbacaan yang lebih baik
plt.show()

"""# Model Training and Evaluation"""

# Mengimpor library yang diperlukan
from sklearn.ensemble import RandomForestRegressor  # Untuk model Random Forest Regressor
from sklearn.tree import DecisionTreeRegressor  # Untuk model Decision Tree Regressor
from sklearn.linear_model import LinearRegression  # Untuk model Linear Regression
from sklearn.neighbors import KNeighborsRegressor  # Untuk model K-Nearest Neighbors
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # Untuk metrik evaluasi
import numpy as np  # Untuk operasi numerik
from sklearn.preprocessing import LabelEncoder  # Untuk encoding kategori
from sklearn.preprocessing import StandardScaler  # Untuk scaling fitur

# Memeriksa apakah 'failures' ada di DataFrame X_train dan X_test
if 'failures' not in X_train.columns:
    # Jika kolom 'failures' tidak ada, kita anggap itu sebagai target atau kolom lain dalam dataset yang perlu ditambahkan
    # Jika kolom tersebut merupakan bagian dari y_train, kita perlu menambahkannya dengan cara yang sesuai
    # Contoh, jika 'failures' adalah target dalam data Anda, tambahkan ke X_train:
    X_train['failures'] = y_train  # Ganti ini dengan sumber data 'failures' yang sesuai
    X_test['failures'] = y_test    # Ganti ini dengan sumber data 'failures' yang sesuai

# Menentukan fitur yang digunakan dalam model
#selected_features = ['G2']

# Memeriksa apakah ada nilai kategorikal dalam data
# Jika 'failures' adalah nilai kategorikal, kita perlu encoding
if X_train['failures'].dtype == 'object':
    # Melakukan encoding untuk kolom 'failures'
    encoder = LabelEncoder()
    X_train['failures'] = encoder.fit_transform(X_train['failures'])
    X_test['failures'] = encoder.transform(X_test['failures'])

# Membuat subset data latih dan uji hanya dengan fitur yang dipilih
X_train_selected = X_train[selected_columns]
X_test_selected = X_test[selected_columns]

# Lakukan scaling pada fitur numerik agar model dapat bekerja lebih efisien
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_selected)
X_test_scaled = scaler.transform(X_test_selected)

# Daftar model yang akan dilatih dan dievaluasi
models = [
    ("Random Forest Regressor", RandomForestRegressor(random_state=42)),
    ("Decision Tree Regressor", DecisionTreeRegressor(random_state=42)),
    ("Linear Regression", LinearRegression()),
    ("K-Nearest Neighbors", KNeighborsRegressor(n_neighbors=5))
]

# Iterasi untuk pelatihan dan evaluasi setiap model
for name, model in models:
    # Melatih model dengan data latih yang sudah diskalakan
    model.fit(X_train_scaled, y_train)

    # Membuat prediksi pada data uji
    y_pred = model.predict(X_test_scaled)

    # Menghitung metrik evaluasi
    mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error
    rmse = np.sqrt(mse)  # Root Mean Squared Error
    r2 = r2_score(y_test, y_pred)  # R-squared Score
    mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Mean Absolute Percentage Error

    # Menampilkan hasil evaluasi model
    print(f"Model: {name}")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R^2: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"MAPE: {mape:.4f}%")
    print("-" * 50)